{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPmmtHjsuDrNtP4urE248AU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"rwcxX9NJG56x"},"outputs":[],"source":["import os\n","import torch\n","import numpy as np\n","import pandas as pd\n","import ast\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from google.colab import drive\n","from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.svm import SVC\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, make_scorer\n","from sklearn.utils import resample\n","import time\n","\n","\n","# Gelişmiş Kod Analizcisi\n","class EnhancedCodeAnalyzer:\n","    def __init__(self):\n","        drive.mount('/content/drive', force_remount=True)\n","        self.harmless_path = '/content/drive/MyDrive/yukseklisans/metinmadenciligi/Dataset/gemini_ai/Harmless'\n","        self.malicious_path = '/content/drive/MyDrive/yukseklisans/metinmadenciligi/Dataset/gemini_ai/Malicious'\n","\n","    def load_code_files(self, directory):\n","        code_files = []\n","        for filename in os.listdir(directory):\n","            if filename.endswith('.txt'):\n","                with open(os.path.join(directory, filename), 'r', encoding='utf-8') as file:\n","                    code_files.append(file.read())\n","        return code_files\n","\n","    def prepare_dataset(self):\n","        harmless_codes = self.load_code_files(self.harmless_path)\n","        malicious_codes = self.load_code_files(self.malicious_path)\n","\n","        dataset = pd.DataFrame({\n","            'code': harmless_codes + malicious_codes,\n","            'label': ['harmless']*len(harmless_codes) + ['malicious']*len(malicious_codes)\n","        })\n","        return dataset\n","\n","    def extract_advanced_features(self, code_snippet):\n","        features = {\n","            'code_length': len(code_snippet),\n","            'unique_tokens': len(set(code_snippet.split())),\n","            'line_count': len(code_snippet.split('\\n')),\n","            'complexity_score': code_snippet.count('{') + code_snippet.count('}')\n","                                + code_snippet.count('(') + code_snippet.count(')'),\n","            'function_count': code_snippet.count('def ') + code_snippet.count('function '),\n","            'import_count': code_snippet.count('import '),\n","            'arithmetic_ops': code_snippet.count('+') + code_snippet.count('-') +\n","                              code_snippet.count('*') + code_snippet.count('/')\n","        }\n","        return features\n","\n","    def extract_ast_features(self, code_snippet):\n","        try:\n","            tree = ast.parse(code_snippet)\n","        except SyntaxError:\n","            return {'num_functions': 0, 'num_loops': 0, 'num_conditionals': 0}\n","\n","        class ASTFeatureExtractor(ast.NodeVisitor):\n","            def __init__(self):\n","                self.num_functions = 0\n","                self.num_loops = 0\n","                self.num_conditionals = 0\n","\n","            def visit_FunctionDef(self, node):\n","                self.num_functions += 1\n","                self.generic_visit(node)\n","\n","            def visit_For(self, node):\n","                self.num_loops += 1\n","                self.generic_visit(node)\n","\n","            def visit_While(self, node):\n","                self.num_loops += 1\n","                self.generic_visit(node)\n","\n","            def visit_If(self, node):\n","                self.num_conditionals += 1\n","                self.generic_visit(node)\n","\n","        extractor = ASTFeatureExtractor()\n","        extractor.visit(tree)\n","\n","        return {\n","            'num_functions': extractor.num_functions,\n","            'num_loops': extractor.num_loops,\n","            'num_conditionals': extractor.num_conditionals\n","        }\n","\n","    def prepare_manual_ast_features(self, dataset):\n","        manual_features = dataset['code'].apply(self.extract_advanced_features).apply(pd.Series)\n","        ast_features = dataset['code'].apply(self.extract_ast_features).apply(pd.Series)\n","        combined_features = np.hstack([manual_features, ast_features])\n","        return combined_features\n","\n","    def prepare_labels(self, dataset):\n","        return dataset['label'].apply(lambda x: 1 if x == 'malicious' else 0).values\n","\n","# Ana İşlem\n","analyzer = EnhancedCodeAnalyzer()\n","dataset = analyzer.prepare_dataset()\n","X = analyzer.prepare_manual_ast_features(dataset)\n","y = analyzer.prepare_labels(dataset)\n","\n","# Veriyi eğitim ve test kümelerine ayırma\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Ölçeklendirme (StandardScaler)\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","# Sınıflandırıcılar ve GridSearch hiperparametreleri\n","classifiers = {\n","    'GaussianNB': GaussianNB(),\n","    'Logistic Regression': LogisticRegression(random_state=42),\n","    'KNN': KNeighborsClassifier(),\n","    'Decision Tree': DecisionTreeClassifier(random_state=42),\n","    'SVM': SVC(random_state=42),\n","    'Random Forest': RandomForestClassifier(random_state=42),\n","    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n","    'AdaBoost': AdaBoostClassifier(random_state=42)\n","}\n","\n","# Özelleştirilmiş değerlendirme metrikleri\n","scoring = {\n","    'precision': make_scorer(precision_score, pos_label=1),\n","    'recall': make_scorer(recall_score, pos_label=1),\n","    'accuracy': make_scorer(accuracy_score),\n","    'f1': make_scorer(f1_score, pos_label=1)\n","}\n","\n","# GridSearch için hiperparametre aralıkları (DİKKAT: Uygun aralıkları belirleyin!)\n","param_grids = {\n","    'GaussianNB': {},\n","    'Logistic Regression': {\n","        'C': [0.1, 1, 10],\n","        'penalty': ['l2'],\n","        'solver': ['liblinear', 'lbfgs']\n","    },\n","    'KNN': {\n","        'n_neighbors': [3, 5, 7, 9],\n","        'weights': ['uniform', 'distance'],\n","        'metric': ['euclidean', 'manhattan']\n","    },\n","     'Decision Tree':{\n","        'max_depth': [None, 5, 10],\n","        'min_samples_split': [2, 5],\n","        'min_samples_leaf': [1, 2]\n","    },\n","        'SVM': {\n","        'C': [0.1, 1, 10],\n","        'gamma': ['scale', 'auto'],\n","        'kernel': ['rbf', 'linear']\n","    },\n","    'Random Forest': {\n","        'n_estimators': [50, 100],\n","        'max_depth': [None, 5, 10],\n","        'min_samples_split': [2, 5],\n","        'min_samples_leaf': [1, 2]\n","    },\n","    'Gradient Boosting': {\n","        'n_estimators': [50, 100],\n","        'learning_rate': [0.01, 0.1],\n","        'max_depth': [3, 5]\n","    },\n","        'AdaBoost': {\n","        'n_estimators': [50, 100, 200],\n","        'learning_rate': [0.01, 0.1, 0.2]\n","    }\n","}\n","\n","# Modelleri eğit ve değerlendir (Grid Search ile)\n","results = {}\n","grid_search_results = {}\n","\n","for name, clf in classifiers.items():\n","    print(f\"\\n{name} için GridSearch çalıştırılıyor...\")\n","    param_grid = param_grids[name]\n","\n","    # Stratified K-Fold oluştur\n","    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","\n","    grid_search = GridSearchCV(\n","        estimator=clf,\n","        param_grid=param_grid,\n","        scoring=scoring,\n","        refit='f1',  # En iyi modeli F1 skora göre seç\n","        cv=cv,  # Stratified K-Fold kullan\n","        verbose=2,\n","        n_jobs=-1\n","    )\n","\n","    start_time = time.time()\n","    grid_search.fit(X_train_scaled, y_train)\n","    end_time = time.time()\n","    training_time = end_time - start_time\n","\n","    # En iyi modeli al\n","    best_model = grid_search.best_estimator_\n","\n","    # Test seti üzerinde değerlendirme\n","    y_pred = best_model.predict(X_test_scaled)\n","    accuracy = accuracy_score(y_test, y_pred)\n","    precision = precision_score(y_test, y_pred)\n","    recall = recall_score(y_test, y_pred)\n","    f1 = f1_score(y_test, y_pred)\n","\n","    results[name] = {\n","        'accuracy': accuracy,\n","        'precision': precision,\n","        'recall': recall,\n","        'f1': f1\n","    }\n","\n","    # En iyi skor ve parametreleri kaydet\n","    best_params = grid_search.best_params_\n","    best_f1_score = grid_search.cv_results_['mean_test_f1'][grid_search.best_index_]\n","    best_precision = grid_search.cv_results_['mean_test_precision'][grid_search.best_index_]\n","    best_recall = grid_search.cv_results_['mean_test_recall'][grid_search.best_index_]\n","    best_accuracy = grid_search.cv_results_['mean_test_accuracy'][grid_search.best_index_]\n","\n","    grid_search_results[name] = {\n","        'best_params': best_params,\n","        'metrics': {\n","            'f1': best_f1_score,\n","            'precision': best_precision,\n","            'recall': best_recall,\n","            'accuracy': best_accuracy\n","        },\n","        'training_time': training_time\n","    }\n","\n","\n","# Sonuçları yazdırma\n","print(\"\\nModel Sonuçları (Test Seti Üzerinde):\")\n","for name, metrics in results.items():\n","    print(f\"\\n{name}:\")\n","    for metric, value in metrics.items():\n","        print(f\"  {metric}: {value:.4f}\")\n","\n","# GridSearch sonuçlarını yazdırma\n","print(\"\\nTüm Modeller İçin GridSearch Sonuçları:\")\n","for model_name, result in grid_search_results.items():\n","    print(f\"\\nModel: {model_name}\")\n","    if 'best_params' in result:\n","        print(f\"  En İyi Hiperparametreler = {result['best_params']}\")\n","    print(f\"  Performans:\")\n","    for metric, score in result['metrics'].items():\n","        print(f\"    {metric.capitalize()}: {score:.4f}\")\n","    print(f\"   Eğitim Süresi: {result['training_time']:.2f} saniye\")\n","\n","# CSV Dosyasına Kaydetme\n","output_dir = \"/content/drive/MyDrive/yukseklisans/metinmadenciligi/Dataset/gemini_ai/feature_outputs/manuel\"\n","os.makedirs(output_dir, exist_ok=True)\n","\n","df = pd.DataFrame(X_train_scaled)\n","df['label'] = y_train  # Eğitim etiketlerini ekle\n","csv_path = os.path.join(output_dir, \"manual_ast_features_train.csv\")\n","df.to_csv(csv_path, index=False)\n","print(f\"✔ 'manual+ast' training feature set kaydedildi: {csv_path}\")\n","\n","df_test = pd.DataFrame(X_test_scaled)\n","df_test['label'] = y_test  # Test etiketlerini ekle\n","csv_path = os.path.join(output_dir, \"manual_ast_features_test.csv\")\n","df_test.to_csv(csv_path, index=False)\n","print(f\"✔ 'manual+ast' test feature set kaydedildi: {csv_path}\")\n","\n","# Görselleştirme (İlk 2 Feature ile)\n","def visualize_features(features, labels, output_dir=\"/content/drive/MyDrive/yukseklisans/metinmadenciligi/Dataset/gemini_ai/feature_outputs/manuel\", filename=\"manual_ast_feature_visualization.png\"):\n","    os.makedirs(output_dir, exist_ok=True)\n","    df = pd.DataFrame(features[:, :2], columns=['Feature_1', 'Feature_2'])\n","    df['label'] = labels\n","\n","    plt.figure(figsize=(8, 6))\n","    sns.scatterplot(x=\"Feature_1\", y=\"Feature_2\", hue=\"label\", data=df, palette=\"coolwarm\", alpha=0.7)\n","    plt.title(\"Feature Distribution - manual+ast\")\n","    plt.xlabel(\"Feature 1\")\n","    plt.ylabel(\"Feature 2\")\n","    plt.legend(title=\"Label\")\n","\n","    image_path = os.path.join(output_dir, filename)\n","    plt.savefig(image_path)\n","    print(f\"📊 Feature visualization saved: {image_path}\")\n","    plt.show()\n","\n","visualize_features(X_train_scaled, y_train, output_dir, \"manual_ast_feature_visualization_train.png\")\n","visualize_features(X_test_scaled, y_test, output_dir, \"manual_ast_feature_visualization_test.png\")"]}]}